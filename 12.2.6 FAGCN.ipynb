{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 超参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#其他与GraphSAGE参数设置相同\n",
    "eps = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 数据集处理与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "dataset = Planetoid(root='./data', name='Cora')\n",
    "data = dataset[0]\n",
    "num_features = dataset.num_features\n",
    "num_classes = dataset.num_classes\n",
    "\n",
    "# 获取输入输出维度\n",
    "input_dim = dataset.num_node_features\n",
    "output_dim = dataset.num_classes\n",
    "\n",
    "# 获取训练集和测试集的索引\n",
    "idx_train = data.train_mask.nonzero(as_tuple=False).view(-1)\n",
    "idx_test = data.test_mask.nonzero(as_tuple=False).view(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 构建卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FALayer(MessagePassing):\n",
    "    def __init__(self, data, num_hidden):\n",
    "        super(FALayer, self).__init__(aggr='add') # 使用add聚合\n",
    "        self.data = data\n",
    "        self.gate = nn.Linear(2 * num_hidden, 1) # 门控机制\n",
    "        self.row, self.col = data.edge_index # 边的索引\n",
    "        self.norm_degree = degree(self.row, num_nodes=data.y.shape[0]).clamp(min=1) # 计算度数并进行归一化\n",
    "        self.norm_degree = torch.pow(self.norm_degree, -0.5)\n",
    "        nn.init.xavier_normal_(self.gate.weight, gain=1.414) # 初始化权重\n",
    "\n",
    "    def forward(self, h): \n",
    "        h2 = torch.cat([h[self.row], h[self.col]], dim=1) # 拼接节点特征\n",
    "        g = torch.tanh(self.gate(h2)).squeeze() # 计算门控值\n",
    "        norm = g * self.norm_degree[self.row] * self.norm_degree[self.col] # 计算归一化值\n",
    "        return self.propagate(self.data.edge_index, size=(h.size(0), h.size(0)), x=h, norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1,1) * x_j # 消息传递\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out # 更新节点特征\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FAGCN(nn.Module):\n",
    "    def __init__(self, data, num_features, num_hidden, num_classes, eps):\n",
    "        super(FAGCN, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.layers = nn.ModuleList()\n",
    "        # 两层FAGCN\n",
    "        self.layers.append(FALayer(data, num_hidden))\n",
    "        self.layers.append(FALayer(data, num_hidden))\n",
    "        # 两层全连接层\n",
    "        self.t1 = nn.Linear(num_features, num_hidden)\n",
    "        self.t2 = nn.Linear(num_hidden, num_classes)\n",
    "        self.reset_parameters()\n",
    "    def reset_parameters(self):\n",
    "        # 初始化权重\n",
    "        nn.init.xavier_normal_(self.t1.weight, gain=1.414)\n",
    "        nn.init.xavier_normal_(self.t2.weight, gain=1.414)\n",
    "    def forward(self, h):\n",
    "        h = torch.relu(self.t1(h))\n",
    "        raw = h\n",
    "        # 第一层FAGCN和残差连接\n",
    "        h = self.layers[0](h)\n",
    "        h = self.eps * raw + h\n",
    "        # 第二层FAGCN和残差连接\n",
    "        h = self.layers[1](h)\n",
    "        h = self.eps * raw + h\n",
    "        \n",
    "        h = self.t2(h)\n",
    "        return F.log_softmax(h, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 模型训练和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    # 前向传播\n",
    "    net.train()\n",
    "    logp = net(data.x)\n",
    "    loss = F.nll_loss(logp[idx_train], data.y[idx_train])\n",
    "    train_acc = accuracy(logp[idx_train], data.y[idx_train])\n",
    "    # 反向传播\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # 计算准确率\n",
    "    net.eval()\n",
    "    logp = net(data.x)\n",
    "    test_acc = accuracy(logp[idx_test], data.y[idx_test])\n",
    "    print(\"Epoch {:03d} | Loss {:.4f} | Train {:.4f} | Test {:.4f} \".format(\n",
    "        epoch, loss.item(), train_acc, test_acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ggl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
