{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 超参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "n_epoch = 200\n",
    "hidden_dim = 16\n",
    "l2_coef = 5e-4\n",
    "dataset = 'cora'\n",
    "dataset_path = './examples/gcn/'\n",
    "best_model_path = './'\n",
    "self_loops = 1\n",
    "gpu = -1\n",
    "if gpu >= 0:\n",
    "    tlx.set_device(\"GPU\", gpu)\n",
    "else:\n",
    "    tlx.set_device(\"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 数据集处理与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammagl.datasets import Planetoid\n",
    "from gammagl.utils import add_self_loops, mask_to_index\n",
    "\n",
    "dataset = Planetoid(args.dataset_path, args.dataset)  \n",
    "# 从gammagl库中导入Planetoid类，用于加载和处理图数据集如Cora\n",
    "graph = dataset[0]\n",
    "# 在图的每个节点上添加自环（self-loop）。\n",
    "edge_index, _ = add_self_loops(graph.edge_index,\n",
    "num_nodes=graph.num_nodes,\n",
    "n_loops=args.self_loops)\n",
    "train_idx = mask_to_index(graph.train_mask)  \n",
    "test_idx = mask_to_index(graph.test_mask)\n",
    "val_idx = mask_to_index(graph.val_mask)\n",
    "# 将布尔掩码序列转换为索引序列的形式\n",
    "data = {\n",
    "    \"x\": graph.x,\n",
    "    \"y\": graph.y,\n",
    "    \"edge_index\": edge_index,\n",
    "    \"train_idx\": train_idx,\n",
    "    \"test_idx\": test_idx,\n",
    "    \"val_idx\": val_idx,\n",
    "    \"num_nodes\": graph.num_nodes,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 构建卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorlayerx as tlx\n",
    "from gammagl.utils import degree\n",
    "from gammagl.layers.conv import MessagePassing\n",
    "from gammagl.mpops import *\n",
    "import tensorlayerx.nn as nn\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels): \n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        # 使用Xavier uniform初始化权重矩阵\n",
    "        self.linear = tlx.layers.Linear(out_features=out_channels,\n",
    "        in_features=in_channels,\n",
    "        W_init='xavier_uniform',\n",
    "        b_init=None)\n",
    "        initor = tlx.initializers.Zeros() # 创建一个将所有值初始化为零的初始化器\n",
    "        # 调用_get_weights方法来获取或创建偏置项的权重\n",
    "        self.bias = self._get_weights(\"bias\", shape=(1,self.out_channels), init=initor)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None, num_nodes=None):\n",
    "        x = self.linear(x) # 对输入特征进行一次线性变换\n",
    "        src, dst = edge_index[0], edge_index[1] # 提取源节点/目标节点序列\n",
    "        edge_weight = tlx.ones(shape=(tlx.get_tensor_shape(edge_index)[1], 1)) \n",
    "        edge_weight = tlx.reshape(edge_weight,(-1,)) # 将边权重变为一维数组\n",
    "        weights = edge_weight\n",
    "        num_nodes = tlx.get_tensor_shape(x)[0] # 获取输入特征x的节点数量\n",
    "        eg = degree(src, num_nodes=num_nodes, dtype = tlx.float32) # 计算源节点的度\n",
    "        norm = tlx.pow(deg, -0.5) # 使用度数的-0.5次方作为归一化系数\n",
    "        weights = tlx.ops.gather(norm, src) * tlx.reshape(edge_weight, (-1,)) # 应用归一化\n",
    "        out = self.propagate(x, edge_index,\n",
    "        edge_weight=weights,\n",
    "        num_nodes=num_nodes) #消息传递和聚合\n",
    "        out += self.bias # 如果add_bias为True，则将偏置项加到输出\n",
    "        return out\n",
    "\n",
    "    def message_aggregate(self, x, edge_index, edge_weight=None, aggr=\"sum\"):\n",
    "        edge_weight = tlx.ones(shape=(tlx.get_tensor_shape(edge_index)[1],),\n",
    "        dtype=tlx.float32)\n",
    "        out = gspmm(edge_index, edge_weight, x, aggr) # 使用融合算子\n",
    "        return out\n",
    "\n",
    "class GCNModel(tlx.nn.Module):\n",
    "    def __init__(self, feature_dim,\n",
    "        hidden_dim,\n",
    "        num_class,\n",
    "        name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.conv1 = GCNConv(feature_dim, hidden_dim) # 构建输入层\n",
    "        self.conv2 = GCNConv(hidden_dim, num_class) # 构建输出层\n",
    "        self.relu = tlx.ReLU() # 构建激活函数\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, num_nodes):\n",
    "        x = self.conv1(x, edge_index, edge_weight, num_nodes)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_weight, num_nodes)\n",
    "        return x\n",
    "net = GCNModel(feature_dim=dataset.num_node_features,\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        num_class=dataset.num_classes,\n",
    "        name=\"GCN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorlayerx.model import WithLoss, TrainOneStep \n",
    "class SemiSpvzLoss(WithLoss):\n",
    "    def __init__(self, net, loss_fn):\n",
    "        super(SemiSpvzLoss,   self).__init__(backbone=net, loss_fn=loss_fn)\n",
    "    def forward(self, data, y):\n",
    "        logits = self.backbone_network(data['x'],\n",
    "        data['edge_index'],\n",
    "        None,\n",
    "        data['num_nodes']\n",
    "        )\n",
    "        # 根据输入的节点特征、边的连接信息等数据计算出模型的输出（logits）\n",
    "        train_logits = tlx.gather(logits, data['train_idx'])  \n",
    "        # 通过tlx.gather从标签中选择出训练集的真实标签 \n",
    "        train_y = tlx.gather(data['y'], data['train_idx']) \n",
    "        loss = self._loss_fn(train_logits, train_y)\n",
    "        return loss\n",
    "\n",
    "train_weights = net.trainable_weights\n",
    "loss_func = SemiSpvzLoss(net,   tlx.losses.softmax_cross_entropy_with_logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 设置优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tlx.optimizers.Adam(lr=args.lr, weight_decay=args.l2_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 设置模型评测指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc(logits, y, metrics):\n",
    "    metrics.update(logits, y)\n",
    "    rst = metrics.result()\n",
    "    metrics.reset()\n",
    "    return rst\n",
    "metrics = tlx.metrics.Accuracy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 定义模型训练、推理流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_step = TrainOneStep(loss_func, optimizer, train_weights)\n",
    "best_val_acc = 0\n",
    "for epoch in range(args.n_epoch):\n",
    "    net.set_train()\n",
    "    train_loss = train_one_step(data, graph.y) # 进行每轮训练\n",
    "    net.set_eval()\n",
    "    logits = net(data['x'], data['edge_index'], None, data['num_nodes']) # 执行模型的前向传播计算，生成预测的输出（logits）\n",
    "    val_logits = tlx.gather(logits, data['val_idx'])\n",
    "    val_y = tlx.gather(data['y'], data['val_idx'])\n",
    "    val_acc = calculate_acc(val_logits, val_y, metrics)# 计算验证集上的准确率。val_logits是验证集的预测值，val_y是验证集的真实标签，metrics是评估标准\n",
    "    print(\"Epoch [{:0>3d}] \".format(epoch+1)\\\n",
    "        + \" train loss: {:.4f}\".format(train_loss.item())\\\n",
    "        + \" val acc: {:.4f}\".format(val_acc))\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        # 保留验证集上表现最好的模型参数,作为测试集采用的模型参数\n",
    "        net.save_weights(args.best_model_path+net.name+\".npz\", format='npz_dict')\n",
    "\n",
    "net.load_weights(args.best_model_path+net.name+\".npz\", format='npz_dict')\n",
    "net.set_eval()\n",
    "logits = net(data['x'], data['edge_index'], None, data['num_nodes'])\n",
    "test_logits = tlx.gather(logits, data['test_idx'])\n",
    "test_y = tlx.gather(data['y'], data['test_idx'])\n",
    "test_acc = calculate_acc(test_logits, test_y, metrics)\n",
    "print(\"Test acc: {:.4f}\".format(test_acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ggl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
