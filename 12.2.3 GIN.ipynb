{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 超参数设置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "n_epoch = 200\n",
    "hidden_dim = 16\n",
    "l2_coef = 5e-4\n",
    "dataset = 'cora'\n",
    "dataset_path = './examples/gcn/'\n",
    "best_model_path = './'\n",
    "self_loops = 1\n",
    "gpu = -1\n",
    "if gpu >= 0:\n",
    "    tlx.set_device(\"GPU\", gpu)\n",
    "else:\n",
    "    tlx.set_device(\"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 数据集处理与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammagl.loader import DataLoader\n",
    "from gammagl.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset(path, name=args.dataset)\n",
    "dataset_unit = len(dataset) // 10\n",
    "train_dataset = dataset[2 * dataset_unit:]\n",
    "val_dataset = dataset[:dataset_unit]\n",
    "test_dataset = dataset[dataset_unit: 2 * dataset_unit]\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 构建卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorlayerx as tlx\n",
    "from .mlp import MLP\n",
    "from gammagl.layers.conv import MessagePassing\n",
    "from gammagl.layers.pool.glob import global_sum_pool\n",
    "\n",
    "class GINConv(MessagePassing):\n",
    "    def __init__(self, nn, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.nn = nn\n",
    "\n",
    "    def forward(self, x, edge_index, size=None):\n",
    "        if not isinstance(x, (list, tuple)):\n",
    "            x = (x, x)\n",
    "        out = self.propagate(x=x[0], edge_index=edge_index, size=size) # 消息传递\n",
    "        x_r = x[1]\n",
    "        out += x_r # 跳跃连接部分加到输出上，缓解梯度消失或梯度爆炸问题\n",
    "        return self.nn(out)\n",
    "\n",
    "    def message(self, x, edge_index):\n",
    "        return tlx.gather(x, edge_index[0, :])\n",
    "\n",
    "class GINModel(tlx.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, name=\"GIN\"):\n",
    "        super(GINModel, self).__init__(name=name)\n",
    "        self.convs = tlx.nn.ModuleList()\n",
    "        mlp = MLP([in_channels, hidden_channels, hidden_channels]) #构建多层感知机\n",
    "        self.convs.append(GINConv(nn=mlp, train_eps=False))\n",
    "        in_channels = hidden_channels\n",
    "        self.mlp = MLP([hidden_channels, hidden_channels, out_channels],\n",
    "        norm=None, dropout=0.5)\n",
    "        self.relu = tlx.ReLU()\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = tlx.random_normal((batch.shape[0], 1), dtype=tlx.float32)\n",
    "        for conv in self.convs:\n",
    "            x = self.relu(conv(x, edge_index))\n",
    "        x = global_sum_pool(x, batch)\n",
    "        return self.mlp(x)\n",
    "\n",
    "net = GINModel(in_channels=max(dataset.num_features, 1),\n",
    "    hidden_channels=args.hidden_dim,\n",
    "    out_channels=dataset.num_classes,\n",
    "    name=\"GIN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 定义损失函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorlayerx.model import WithLoss, TrainOneStep \n",
    "class SemiSpvzLoss(WithLoss):\n",
    "    def __init__(self, net, loss_fn):\n",
    "        super(SemiSpvzLoss,   self).__init__(backbone=net, loss_fn=loss_fn)\n",
    "    def forward(self, data, y):\n",
    "        logits = self.backbone_network(data['x'],\n",
    "        data['edge_index'],\n",
    "        None,\n",
    "        data['num_nodes']\n",
    "        )\n",
    "        # 根据输入的节点特征、边的连接信息等数据计算出模型的输出（logits）\n",
    "        train_logits = tlx.gather(logits, data['train_idx'])  \n",
    "        # 通过tlx.gather从标签中选择出训练集的真实标签 \n",
    "        train_y = tlx.gather(data['y'], data['train_idx']) \n",
    "        loss = self._loss_fn(train_logits, train_y)\n",
    "        return loss\n",
    "\n",
    "train_weights = net.trainable_weights\n",
    "loss_func = SemiSpvzLoss(net,   tlx.losses.softmax_cross_entropy_with_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 设置优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tlx.optimizers.Adam(lr=args.lr, weight_decay=args.l2_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 设置模型评测指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc(logits, y, metrics):\n",
    "    metrics.update(logits, y)\n",
    "    rst = metrics.result()\n",
    "    metrics.reset()\n",
    "    return rst\n",
    "metrics = tlx.metrics.Accuracy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 定义模型训练、推理流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_step = TrainOneStep(loss_func, optimizer, train_weights)\n",
    "best_val_acc = 0\n",
    "for epoch in range(args.n_epoch):\n",
    "    net.set_train()\n",
    "    train_loss = train_one_step(data, graph.y) # 进行每轮训练\n",
    "    net.set_eval()\n",
    "    logits = net(data['x'], data['edge_index'], None, data['num_nodes']) # 执行模型的前向传播计算，生成预测的输出（logits）\n",
    "    val_logits = tlx.gather(logits, data['val_idx'])\n",
    "    val_y = tlx.gather(data['y'], data['val_idx'])\n",
    "    val_acc = calculate_acc(val_logits, val_y, metrics)# 计算验证集上的准确率。val_logits是验证集的预测值，val_y是验证集的真实标签，metrics是评估标准\n",
    "    print(\"Epoch [{:0>3d}] \".format(epoch+1)\\\n",
    "        + \" train loss: {:.4f}\".format(train_loss.item())\\\n",
    "        + \" val acc: {:.4f}\".format(val_acc))\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        # 保留验证集上表现最好的模型参数,作为测试集采用的模型参数\n",
    "        net.save_weights(args.best_model_path+net.name+\".npz\", format='npz_dict')\n",
    "\n",
    "net.load_weights(args.best_model_path+net.name+\".npz\", format='npz_dict')\n",
    "net.set_eval()\n",
    "logits = net(data['x'], data['edge_index'], None, data['num_nodes'])\n",
    "test_logits = tlx.gather(logits, data['test_idx'])\n",
    "test_y = tlx.gather(data['y'], data['test_idx'])\n",
    "test_acc = calculate_acc(test_logits, test_y, metrics)\n",
    "print(\"Test acc: {:.4f}\".format(test_acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ggl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
